{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа по анализу Twitter\n",
    "\n",
    "Целью лабораторной работы является научиться применять методы обучения с учителем (supervised learning) для задачи анализа тональностей, а также освоить специализированный инструментарий для компьютерной лингвистики и машинного обучения.\n",
    "\n",
    "- Загрузить с использованием csv файлов твиты.\n",
    "- Провести предобработку корпуса (удаление стоп-слов, и т.д.)\n",
    "- Используя выбранную модель репрезентации получить матричное представление.\n",
    "- Используя изученные классификаторы получить численные оценки точности, полноты и F-меры.\n",
    "- Объяснить полученные результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import preprocessor as p\n",
    "p.set_options(p.OPT.URL, p.OPT.MENTION, p.OPT.RESERVED, p.OPT.EMOJI,p.OPT.SMILEY,p.OPT.NUMBER,p.OPT.HASHTAG)\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Выгрузим все данные, объединим их в один датафрейм и посмотрим на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = pd.read_csv(\"positive.csv\", \";\", header=None)\n",
    "negative = pd.read_csv(\"negative.csv\", \";\", header=None)\n",
    "result = pd.concat([positive, negative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.columns = ['id', 'tdate', 'tname', 'ttext', 'polarity', 'trep', 'trtw', 'tfav', 'tstcount', 'tfol', 'tfriends', 'listcount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = result.sample(frac=1).reset_index(drop=True)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь разобьем наш набор данных случайным образом на train и test выборки с отношением 80/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(result, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дальнейшего анализа нам нужны только текст каждого твита и его категория, поэтому удаляем все остальные колонки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = train_data.drop(['id', 'tdate', 'tname', 'trep', 'trtw', 'tfav', 'tstcount', 'tfol', 'tfriends', 'listcount'], axis = 1)\n",
    "test_data = test_data.drop(['id', 'tdate', 'tname', 'trep', 'trtw', 'tfav', 'tstcount', 'tfol', 'tfriends', 'listcount'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Теперь, когда данные приведены к единому виду, необходимо выполнить предобработку текста: привести текст к нижнему регистру, очистить его от всего лишнего - спец символов, чисел, ссылок и зарезервированных слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка текста"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Возьмем твит из тренировочной выборки и посмотрим на него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['ttext'][7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Текст необходимо очистить. Для этого воспользуемся библиотекой для предобработки твитов - https://github.com/s/preprocessor  \n",
    "Ее особенность в том, что она позволяет удалять ссылки, хэштеги, упоминания и т.д. \n",
    "Код применения ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p.clean(train_data['ttext'][7].lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Теперь воспользуемся токенайзером, который очистит текст от оставшихся ненужных символов и соединим получившиеся токены в предложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "' '.join(CountVectorizer().build_tokenizer()(p.clean(train_data['ttext'][7].lower())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Теперь сделаем то же самое со всеми данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['ttext'] = train_data['ttext'].apply(lambda t: ' '.join(CountVectorizer().build_tokenizer()(p.clean(t.lower()))))\n",
    "test_data['ttext'] = test_data['ttext'].apply(lambda t: ' '.join(CountVectorizer().build_tokenizer()(p.clean(t.lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь удалим стоп-слова из наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"russian\"))  # load stopwords\n",
    "train_data['ttext'] = train_data['ttext'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "test_data['ttext'] = test_data['ttext'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF представление твитов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Далее, представим твиты в виде TF-IDF. Для этого, воспользуемся TfidfVectorizer'ом.\n",
    "* Установим значения min_df = 5, чтобы отбросить слова, которые появляются реже 5 раз."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TF_IDF = TfidfVectorizer()\n",
    "TF_IDF.fit(list(train_data['ttext']) + list(test_data['ttext']))\n",
    "X_train = TF_IDF.transform(list(train_data['ttext']))\n",
    "X_test = TF_IDF.transform(list(test_data['ttext']))\n",
    "\n",
    "y_train = list(train_data['polarity'])\n",
    "y_test = list(test_data['polarity'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Логистическая регрессия *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.69      0.75      0.72     20672\n",
      "          1       0.77      0.72      0.75     24695\n",
      "\n",
      "avg / total       0.74      0.73      0.73     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(prediction,y_test,target_names=['-1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Наивный Байесовский классификатор*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.74      0.71      0.73     23159\n",
      "          1       0.71      0.74      0.73     22208\n",
      "\n",
      "avg / total       0.73      0.73      0.73     45367\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(prediction,y_test,target_names=['-1', '1']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Метод опорных векторов*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'linear', C=0.8)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *linear*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(prediction,y_test,target_names=['-1', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = SVC(kernel = 'rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* *rbf*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(metrics.classification_report(prediction,y_test,target_names=['-1', '1']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
