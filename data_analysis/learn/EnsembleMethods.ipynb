{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ансамбльные методы в машинном обучении\n",
    "\n",
    "Семантическим значением слова \"ансамбль\" (ensemble) является понятие группы. Ансамбльные методы (ensemble methods) включают в себя группу предиктивных моделей для достижения лучшей точности и стабильности модели.\n",
    "\n",
    "Известно также, что ансамбльные методы дают высокий прирост производительности моделям, основанных на деревьях решений.\n",
    "\n",
    "Также, как и другие модели, модели основанные на деревьях решений также страдают от \"проклятия\" смещения-дисперсии.\n",
    "\n",
    "**Контрольный вопрос: сфорулируйте понятия смещения (bias) и дисперсии (variance) в контексте дилеммы смещения-дисперсии (bias-variance tradeoff)**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При построении \"небольшого\" дерева решения, вы получите модель с малой дисперсией (low variance) и высоким смещением (high bias). Как сбалансировать компромисс между смещением и дисперсией?\n",
    "\n",
    "Обычно, при увеличении сложности модели, вы увидете уменьшение ошибки предсказания, благодаря уменьшению смещения (bias) модели. По мере увеличения сложности модели, вы придете к переобучению моделе и модель будет страдать от высокой дисперсии (high variance).\n",
    "\n",
    "В целом, хорошая модель должна поддерживать баланс между этими двумя типами ошибок. Это известно как компромисс между смещением и дисперсией (bias-variance tradeoff).\n",
    "Ансамбльные методики обучения являются одним из способов прийти к этому компромиссу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/model_complexity.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ансамбльные алгоритмы включают в себя ряд широко используемых методов:\n",
    "* Bagging\n",
    "* Boosting\n",
    "* Stacking\n",
    "\n",
    "Но сначала разберемся с первым вопросом\n",
    "\n",
    "\n",
    "## Что такое ансамбльная модель?\n",
    "\n",
    "Попытаемся понять это, решением задачи классификации.\n",
    "\n",
    "**Проблема: найти множество правил для классификации спама.**\n",
    "\n",
    "**Решение:** мы можем сгенерировать различные правила для классификации спама. Рассмотрим некоторые из них:\n",
    "\n",
    "Спам:\n",
    "* Имеет общую длину менее чем 20 слов;\n",
    "* В письме содержатся только картинки;\n",
    "* Имеются специфические слова (например _make money and grow_ или _reduce your fat_);\n",
    "* Значительное число ошибок в письме\n",
    "\n",
    "Не спам:\n",
    "* Письмо от odurandin@hse.ru :)\n",
    "* Письма от членов вашей семьи или от кого-либо из адресной книги.\n",
    "\n",
    "Итак, выше приведены некоторые общие правила для фильтрации спама. Как вы думаете, могут ли эти правила независимо друг от друга предсказать корректный класс (спам или не спам)?\n",
    "\n",
    "Большинство скажет, что нет и будут правы!\n",
    "Лишь комбинация этих правил даст устойчивое предсказание, по сравнению с предсказанием, выполненным на базе индивидуальных правил. В этом и состоит принцип **ансамбльного обучения**. Ансамбльные модели комбинируют несколько индивидуальных моделей вместе и обеспечивают, таким образом, мощность предсказания.\n",
    "![](https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2017/02/12152925/meme.jpg)\n",
    "\n",
    "Если вы хотите провести аналогию с реальностью: более вероятно, что группа людей сделает лучшее решение по сравнению с индивидуумами, особенно в том случае, если члены группы имеют разный опыт. Это истинно и для машинного обучения. Базово, ансамбль - это техника машинного обучения для комбинирования нескольких \"слабых\" моделей, для того, чтобы получить сильную модель. Ансамбльные модели работают лучше, когда мы объединяем модели со слабой корреляцией.\n",
    "\n",
    "#### Ансамбльные модели в реальной жизни\n",
    "##### Теорема Кондорсе \"О жюри присяжных\"\n",
    "\n",
    "(Взято: https://habrahabr.ru/company/ods/blog/324402/)\n",
    "Хорошим примером ансамблей считается теорема Кондорсе «о жюри присяжных» (1784). Если каждый член жюри присяжных имеет независимое мнение, и если вероятность правильного решения члена жюри больше 0.5, то тогда вероятность правильного решения присяжных в целом возрастает с увеличением количества членов жюри и стремится к единице. Если же вероятность быть правым у каждого из членов жюри меньше 0.5, то вероятность принятия правильного решения присяжными в целом монотонно уменьшается и стремится к нулю с увеличением количества присяжных.\n",
    "\n",
    "$$\\mu = \\sum_{i=1}^{N}C^{i}_N p^{i} (1-p)^{N-i}$$\n",
    "\n",
    "* $N$ - количество присяжных;\n",
    "* $p$ - вероятность правильного решения присяжного;\n",
    "* $\\mu$ - вероятность правильного решения жюри;\n",
    "\n",
    "Если $p>0.5$, то $\\mu > p$.\n",
    "Если $N\\to\\infty$, то $\\mu\\to 1$\n",
    "\n",
    "#### Мудрость толпы Ф. Гальтона\n",
    "Давайте рассмотрим ещё один пример ансамблей — \"Мудрость толпы\". Фрэнсис Гальтон в 1906 году посетил рынок, где проводилась некая лотерея для крестьян. \n",
    "\n",
    "Их собралось около 800 человек, и они пытались угадать вес быка, который стоял перед ними. Бык весил 1198 фунтов. Ни один крестьянин не угадал точный вес быка, но если посчитать среднее от их предсказаний, то получим 1197 фунтов.\n",
    "Эту идею уменьшения ошибки применили и в машинном обучении.\n",
    "\n",
    "\n",
    "### Пример алгоритма\n",
    "\n",
    "Хороший пример того, как ансамбльные методы в общем используются для решения проблем из анализа данных - алгоритм **random forest**. Он выполняется намного лучше по сравнению с индивидуальными деревьями решений по классификации нового объекта, где каждое дерево дает \"голос\" для класса, и лес выбирает класс, за который проголосовало большинство (среди всех деревьев в этом лесу). В случае регрессии, берется среднее выходных значений разных деревьев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Типы ансамбльных моделей\n",
    "\n",
    "### Bagging (Bootstrap Aggregating)\n",
    "\n",
    "Bagging представляет собой ансамбльный метод. \n",
    "Сначала, мы создаем случайные подвыборки тренировочных данных (подмножества тренировочной выборки). Затем, строится классификатор для каждого из подмножеств.\n",
    "\n",
    "И, наконец, результаты этих нескольких классификаторов комбинируются с использованием среднего или голосования по большинству. \n",
    "Bagging помогает уменьшить ошибку дисперсии (variance error).\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/bagging.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "Boosting является итеративной техникой, которая настраивает вес каждого наблюдения, на базе последней классификации. Если наблюдение было классифицированно некорректно, оно пытается увеличить вес этого наблюдения, и наоборот.\n",
    "\n",
    "Boosting - в общем уменьшает ошибку смещения (bias error) и строит достаточно сильные предиктивные модели. Тем не менее, они могут иногда переобучаться на тренировочных данных.\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/boosting.png)\n",
    "\n",
    "Наиболее известными примерами бустинга являются алгоритмы AdaBoost и Gradient Boosting.\n",
    "\n",
    "\n",
    "Итак, \n",
    "\n",
    "**Бустинг - итерационный алгоритм, реализующий “сильный” классификатор, который позволяет добиться произвольно малой ошибки обучения (на обучающей выборке) на основе композиции “слабых” классификаторов, каждый из которых лучше, чем просто\n",
    "угадывание, т.е. вероятность правильной классификации больше 0.5**.\n",
    "\n",
    "\n",
    "**Ключевая идея: использование весовой версии одних и тех же обучающих данных вместо случайного выбора их подмножества.**\n",
    "\n",
    "\n",
    "#### Ключевые отличия бэггина от бустинга\n",
    "\n",
    "* Бэггинг - примеры выбираются так, что каждый пример имеет одинаковые шансы попасть в обучающую подвыборку.\n",
    "* Бустинг - обучающая выборка на каждой итерации определяется, исходя из ошибок классификации на предыдущих итерациях.\n",
    "\n",
    "**Ключевая идея бустинга: использование весовой версии одних и тех же обучающих данных вместо случайного выбора их подмножества.\n",
    "Слабые классификаторы образуются последовательно, различаясь только весами обучающих данных, которые зависят от точности предыдущих классификаторов. **\n",
    "Большие веса назначаются “плохим” примерам, что позволяет на каждой итерации сосредоточиться на примерах, неправильно классифицированных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking \n",
    "\n",
    "Стэкинг (stacking) работает в две фазы. \n",
    "\n",
    "Сначала используется несколько базовых классификаторов для предсказания класса. Затем, новый классификатор использует комбинацию предсказаний с целью уменьшения ошибки генерализации (reducing the generalization error).\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/09/stacking-297x300.png)\n",
    "\n",
    "Если говорить более формально, **стэкинг** использует концепцию метаобучения, т.е. пытается обучить каждый классификатор, используя алгоритм, который позволяет обнаружить лучшую комбинацию выходов базовых моделей (Wolpert, 1992).\n",
    "\n",
    "\n",
    "Пусть $D$ - обучающая выборка, и выбрано множество алгоритмов $d_1, \\ldots , d_L$ (базовые классификаторы).\n",
    "Входные данные мета-классификатора - решения базовых классификаторов, т.е. множество меток классов, к которым базовые класcификаторы отнесли описание входного объекта. Множество меток на входе мета-классификатора интерпретируется как\n",
    "множество признаков нового признакового пространства.\n",
    "\n",
    "Обучающие и тестирующие данные для мета-классификатора (мета-данные) формируются базовыми классификаторами на основании тех\n",
    "данных, которыми располагают базовые классификаторы, т.е. метаданные - множества кортежей меток классов, полученных в качестве\n",
    "решений алгоритмами $d_1, \\ldots, d_L$ при их тестировании на множестве входных описаний экземпляров объектов.\n",
    "\n",
    "Каждому кортежу решений ставится метка (кортеж меток) класса, к которому этот объект относится на самом деле. Таким образом, обучающие данные метаклассификатора - векторы вида $(x_{1i},\\ldots, x_{Li}, y_{i})$, где \n",
    "* $i$ - индекс экземпляра из тестовой выборки, \n",
    "* $1,\\ldots,L$ - индексы базовых классификаторов, \n",
    "* $x_{ki}$ - метки классов, полученных базовыми классификаторами $d_k$ для тестируемого примера с номером $i$, \n",
    "* $y_i$ - истинное значение метки тестируемого примера.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Можем ли мы сочетать несколько моделей одного алгоритма машинного обучения?\n",
    "\n",
    "**Да, мы можем комбинировать несколько моделей одних и тех же алгоритмов ML, но комбинирование нескольких прогнозов, генерируемых разными алгоритмами, как правило, дает вам лучшие прогнозы.**\n",
    "\n",
    "Это происходит за счет диверсификации или независимой характером предикторов по отношению друг к другу. Например, предсказания случайного леса (Random Forests), kNN и Naive Bayes могут быть объединены для создания более сильного финального предиктора по сравнению с объединением трех моделей алгоритмов случайного леса (Random Forests). \n",
    "\n",
    "**Ключом к созданию эффективных ансамбльных моделей состоит в их диверсифекации. ** Ансамбльные модели с двумя техниками очень похожими по своей природе техниками будут работать **хуже** чем более диверсифицированные модели.\n",
    "\n",
    "Пример: пусть у нас есть три модели (A, B и C). A, B и C имеют верность предсказания (prediction accuracy) 0.85, 0.80 и 0.55 соответственно.\n",
    "Но A и B являются сильно коррелированны, в то время как C слабо коррелирует как с A, так и с B. Следует ли нам комбинировать модели A и B? \n",
    "\n",
    "Нет, не следует, поскольку эти модели сильно коррелируют между собой. Поэтому, мы не будем комбинировать эти две модели в ансамбль, так как это не поможет уменьшить ошибку генерализации. Вместо этого предпочтительнее скомбинировать A и C или B и C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как найти веса различных моделей в ансамбле?\n",
    "\n",
    "Одним из наиболее сложных моментов при создании ансамбльных моделей является поиск оптимальных весов для сбора базовых моделей. В общем случае, мы предполагаем равными веса для всех моделей и берем среднее предсказаний. Но является ли это лучшим методом работы с подобными моделями?\n",
    "\n",
    "Есть различные методы для поиска оптимальных весов для комбинирования базовых предикторов. Эти методы дают ясное понимание о поиске корректных весов. \n",
    "\n",
    "* Нахождение коллинеарности между базовыми предикторами, и на основе этой таблицы идентифицировать базовые предикторы, которые будут использоваться в ансамбле. После выполнения кросс-валидации идентифицированных базовых предикторов найти веса.\n",
    "* Использовать алгоритм, возвращающий оптимальные веса для базовых предикторов. (Пример алгоритма: https://www.analyticsvidhya.com/blog/2015/08/optimal-weights-ensemble-learner-neural-network/ )\n",
    "* Также можно решить эту проблему с использованием следующих методов:\n",
    "* * Forward selection : https://www.analyticsvidhya.com/blog/2015/09/selection-techniques-ensemble-modelling/\n",
    "* * Selection with Replacement : https://www.analyticsvidhya.com/blog/2015/09/selection-techniques-ensemble-modelling/\n",
    "* * Bagging of ensemble methods : https://www.analyticsvidhya.com/blog/2015/09/selection-techniques-ensemble-modelling/\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преимущества ансамбльных моделей\n",
    "\n",
    "Есть два главных преимущества ансамбльных моделей:\n",
    "* Лучшие показатели точности предсказания\n",
    "* Более стабильная модель\n",
    "\n",
    "Агрегированное мнение ряда моделей является более стабильным (менее подверженным шуму), чем отдельные модели. В финансах, это называется *диверсификацией* - cмешанный портфель нескольких акций будет гораздо менее изменчив, чем лишь один из рынков. \n",
    "\n",
    "По этой же причине модели будут лучше с ансамблем моделей, чем при использовании отдельных предикторов. Тем не менее, необходимо помнить, что ансамбльные модели **также подвержены переобучению**, хотя и в меньшей степени (например, модель bagging менее подвержена переобучению)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вернемся к Bagging'у\n",
    "\n",
    "**Bagging - техника, используемая для снижения дисперсии независимых предикторов посредством комбинации результатов нескольких классификаторов, обученных на подмножествах одной и той же тренировочной выборки.**\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/07/bagging.png)\n",
    "\n",
    "Шаги Bagging'а:\n",
    "1. Создание нескольких наборов данных\n",
    "    * Из исходных тренировочных данных выполняется выборка с заменами (sampling with replacement) и формируются новые наборы данных;\n",
    "    * Новые наборы данных могут иметь лишь часть столбцов (также как и строк), которые, в общем, являются **гиперпараметрами** в модели bagging'а;\n",
    "    * Использование лишь части строк и столбцов помогает сделать более устойчивыми модели, менее подверженные переобучению;\n",
    "2. Построение нескольких классификаторов:\n",
    "    * Классификаторы обучаются на каждом наборе данных (см. пункт 1);\n",
    "    * В общем, одинаковые классификаторы моделируются на разных наборах данных и на основе этого делается предсказание;\n",
    "3. Комбинация классификаторов:\n",
    "    * Предсказания *всех классификаторов* комбинируются с использованием математического ожидания, медианы, или модальной величины, в зависимости от рассматриваемой проблемы.\n",
    "    * Комбинация значений в общем является более устойчивой, чем отдельная модель.\n",
    "   \n",
    "Следует заметить, что *число параметров модели **не является гиперпараметром**.* Большее число моделей всегда лучше или может дать похожие показатели точности чем меньшее число моделей. Можно теоретически показать, что дисперсия комбинированных предсказаний уменьшается как $\\frac{1}{n}$ (где $n$ - число классификаторов) по отношению к исходной дисперсии с использованием тех же допущений.\n",
    "\n",
    "Есть различные реализации моделей bagging'а. Случайный лес (random forest) является одной из них.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Что такое \"Случайный лес\" (Random Forest)?\n",
    "\n",
    "В настоящее время некоторые рассматривают алгоритм случайного леса (Random Forest), как панацею для многих проблем в анализе данных. \n",
    "\n",
    "Random Forest - это универсальный метод машинного обучения, способный решать как задачи регрессии, так и задачи классификации.  Он также может использовать методы уменьшения размерности, обрабатывать пропущенные значения, выбросы и другие важные моменты, которые возникают в ходе анализа и исследования данных. Это тип ансамбльных методов обучения, где группировка слабых моделей способна объединиться в мощную модель.\n",
    "\n",
    "### Как это работает?\n",
    "\n",
    "В алгоритме случайного леса мы \"выращиваем\" несколько деревьев, вместо одного дерева (как это применяется в модели CART). При классификации нового объекта, каждое дерево выполняет классификацию, и сообщаются \"голоса\" для этого класса. Случайный лес выбирает класс по максимальному числу глосов (по всем деревьям в случайном лесу), а в случае регрессии берет среднее значение ответов разных деревьев.\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/09/Forest-Canopy1-850x552.png)\n",
    "\n",
    "Работает это следующим образом. \n",
    "**Каждое** дерево \"выращивается\" в соответствии с шагами:\n",
    "\n",
    "* Пусть размер тренировочной выборки $N$. Тогда, используется выборка из этих $N$ наблюдений, но **берется случайная выборка с заменами (with replacement)**. Эта выборка будет образовывать тренировочную выборку для дерева решений;\n",
    "* Если каждый объект представлен $M$ атрибутам, указывается число $m<M$ такое, что выбирается случайно $m$ атрибутов (из общего числа $M$). Значение $m$ остается константным для леса;\n",
    "* Каждое дерево выращивается до максимального размера и не подвергается стрижке;\n",
    "* Предсказание новых данных проводится агрегацией предсказаний от $n$ деревьев (мажоритарное голосование для классификации, среднее для регрессии).\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/09/all-data-set-850x751.jpg)\n",
    "\n",
    "Ссылка с простым объяснением: https://www.analyticsvidhya.com/blog/2014/06/introduction-random-forest-simplified/\n",
    "\n",
    "### Преимущества алгоритма случайного леса\n",
    "\n",
    "* Алгоритм случайного леса (Random Forest) способен решать как проблемы классификации, так и задачи регрессии и дает приличную оценку для обоих случаев;\n",
    "\n",
    "* Одним из преимуществ алгоритма случайного леса является его способность обрабатывать достаточно большие объемы данных с большой размерностью. Он может обрабатывать тысячи входных атрибутов и идентифицировать самые значимые переменные, как если бы дополнительно использовались методы редукции размерности. Более того, модель выводит важность атрибута, что может быть очень удобной функцией (на некоторых наборах данных);\n",
    "\n",
    "* Алгоритм имеет эффективные мтеоды для оценки пропущенных данных и сохраняет точность даже в том случае, когда часть пропущенных данных достаточно большая;\n",
    "\n",
    "* Алгоритм имеет методы для балансирования ошибок в несбалансированных наборах данных;\n",
    "\n",
    "* Алгоритм случайного леса включает выборку\\сэмплирование (sampling) входных данных с заменами (sampling with replacement), что называется *бутстрапированной выборкой (bootstrap sampling)*. При использовании бутстреп выборки $\\frac{1}{3}$ данных не используется для обучения и поэтому может быть использована для тестирования. Они называются *out of bag samples*. ОШибка, получаемая на этих объектах называется *out of bag error*. \n",
    "Изучение *out of bag error* дает основание показать, что оценка *out of bag error* так же точна, как и использование тестовой выборки того же размера как и тренировочная выборка. Поэтому, использование оценки *out of bag error* устраняет необходимость проводить отдельное тестирование на отложенной выборке.\n",
    "\n",
    "###  Недостатки алгоритма случайного леса\n",
    "\n",
    "* Определенно, алгоритм случайного леса хорошо работает для задач классификации, но не достаточно хорошо справляется с задачей регрессии. Так, в случае регрессии, алгоритм не способен предсказывать значение за пределами диапазона тренировочных данных, вследствие чего алгоритм может переобучиться на наборах данных, содержащих шумы;\n",
    "* Алгоритм случайного леса подобен черному ящику - вы мало можете контролировать что фактически делает модель. В лучшем случае - пробовать разные параметры.\n",
    "\n",
    "### Scikit-learn и Random Forests\n",
    "Фреймворк scikit-learn содержит модуль, включающий в себя ряд ансамбльных алгоритмов, в т.ч. и Random Forests:\n",
    "* Ссылка на документацию по алгоритму: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "* Ссылка на функции модуля: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Еще раз, что такое Boosting?\n",
    "\n",
    "Под термином **бустинг (Boosting)** понимается семейство алгоритмов, которые преобразуют множество слабых классификаторов (weak learning) в сильный.\n",
    "\n",
    "Итак, бустинг комбинирует слабые классификаторы (weak learner \\ base learner), формируя сильный классификатор. Ключевой вопрос, который возникает: *как бустинг находит слабые правила?*\n",
    "\n",
    "Для того, чтобы найти слабые правила, применяются базовые алгоритмы машинного обучения с разными распределениями. Каждый раз, когда базовый алгоритм применяется, он генерирует новое *слабое* правило классификации (weak prediction rule). Это **итеративный процесс**. После нескольких итераций, алгоритм бустинга комбинирует эти слабые правила в единый классификатор.\n",
    "\n",
    "Еще один вопрос, который всплывает: *как мы выбираем разные распределения?*\n",
    "\n",
    "Для выбора правильного распределения, проводятся следующие шаги:\n",
    "\n",
    "1. Базовый классификатор (base learning) берет все распределения и назначает равный вес (weight) каждому наблюдению.\n",
    "* Если есть хотя бы одна ошибка, которая вызываются первым базовым алгоритмом классификации, то мы обращаем большее внимание на объекты, на которых была произведена ошибка классификации (т.е. повышаем вес этим объектам). Затем, мы применяем следующий базовый алгоритм для обучения.\n",
    "* Шаг 2 повторяется до тех пор, пока не наступит предел, наложенный на число базовых алгоритмов, или мы не достигнем высокого показателя точности.\n",
    "\n",
    "В конце концов, мы комбинируем результаты от слабых классификаторов и создаем сильный классификатор, который в конце концов улучшает предсказательную силу модели.\n",
    "\n",
    "Бустинг обращает большее внимание на примеры, который были некорректно проклассифицированы, или имели больше ошибок в процессе работы слабых классификаторов. Есть много алгоритмов, основанных на бустинге.\n",
    "\n",
    "\n",
    "### Типы алгоритмов, основанных на бустинге\n",
    "\n",
    "Есть мнодество алгоритмов, в основе которых лежит методика бустинга. Среди них: \n",
    "* AdaBoost (Adaptive Boosting)\n",
    "* Gradient Tree Boosting\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритм AdaBoost (Adaptive Boosting)\n",
    "\n",
    "На картинке точно изображен алгоритм AdaBoost. \n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/bigd.png)\n",
    "\n",
    "Пробежимся по шагам алгоритма.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 1** Можно увидеть, что мы назначили равные веса каждому наблюдению и применили решающую границу для классификации этих наблюдений на два класса.\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/dd1.png)\n",
    "Решающая граница **D1** представляет собой вертикальную линию (слева). Можно увидеть, что эта вертикальная линия некорректно предсказывает три положительных наблюдения (предсказывая их как отрицательные).\n",
    "В таком случае мы назначаем бОльшие веса этим трем наблюдениям и проводим еще одну решающую границу."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 2** Можно увидеть, что размер трёх некорректно проклассифицированных примеров больше, по сравнению с остальными наблюдениями. Условимся считать, что размер репрезентует вес, который алгоритм дает данному примеру.\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/dd2.png)\n",
    "Итак, вторая решающая граница попытается предсказать эти объекты корректно. Сейчас, вертикальная линия **D2** находится справа и она классифицирует эти три некорректно классифицированных объекта уже корректно. Но опять, она вызывает ошибки неправильной классификации. На этот раз с тремя объектами отрицательного класса. \n",
    "\n",
    "Снова назначаем больший вес этим трем отрицательным объектам и проводим еще одну решающую границу.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 3**. Три объекта с отрицательными классами имеют бОльший вес. Решающая граница **D3** применяется для предсказания этих некорректно классифицированных наблюдений. На этот раз генерируется горизонтальная линия, классифицирующая положительный и отрицательный классы, полагаясь на веса некорректно классифицированных наблюдений.\n",
    "\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/dd3.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Шаг 4**. Итак, комбинируя решающие границы **D1**, **D2** и **D3** для формирования сильного предиктора, имеющего сложные правила (по сравнению с независимыми слабыми классификаторами).\n",
    "\n",
    "Можно увидеть, что этот алгоритм проклассифицировал выборку достаточно хорошо по сравнению с независимым слабыми предикторами.\n",
    "![](https://www.analyticsvidhya.com/wp-content/uploads/2015/11/dd4.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AdaBoost (Adaptive Boosting)** работает по тому же принципу, что проиллюстрирован выше. Он настраивает последовательность слабых классификаторов (weak learners) на разных взвешенных тренировочных данных.\n",
    "\n",
    "Алгоритм начинает классификацию исходных данных и дает равные веса каждому наблюдению. Если предсказание было некорректным для первого слабого классификатора, тогда AdaBoost дает больший вес наблюениям, которые были проклассифицированны некорректно. Будучи итеративным процессом, AdaBoost добавляет слабые классификаторы до тех пор, пока не будет достигнут их лимит, или же не будет достигнута требуемая точность.\n",
    "\n",
    "В основном, с AdaBoost используются слабые классификаторы. Однако, мы можем использовать любые алгоритмы машинного обучения как базовые алгоритмы, если они принимают веса для размеченных тренировочных данных.\n",
    "\n",
    "*Алгоритм AdaBoost может применяться как для решения задач классификации, так и для задач регрессии.*\n",
    "\n",
    "Еще более подробное (но простое объяснение): https://www.analyticsvidhya.com/blog/2015/05/boosting-algorithms-simplified/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### А что там со scikit-learn?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Всё там же, в модуле ensemble: \n",
    "http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "можно найти классы *AdaBoostClassifier* и *AdaBoostRegressor*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier #For Classification\n",
    "from sklearn.ensemble import AdaBoostRegressor #For Regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# x_train, y_train - некоторые обучающие выборки\n",
    "\n",
    "dt = DecisionTreeClassifier() \n",
    "clf = AdaBoostClassifier(n_estimators=100, base_estimator=dt,learning_rate=1)\n",
    "\n",
    "clf.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно настраивать параметры для оптимизации производительности алгоритмов.\n",
    "\n",
    "Ключевые параметры:\n",
    "* **n_estimators** - контролирует число базовых классификаторов (weak learners);\n",
    "* **learning_rate** - контролирует вклад базовых классификаторов в финальную комбинацию. Существует компромисс между параметрами *learning_rate* и *n_estimators*.\n",
    "* **base_estimators** - специфицирует базовый алгоритм.\n",
    "\n",
    "Нужно также помнить, что можно настраивать параметры базовых алгоритмов для оптимизации их производительности.\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting Algorithm: Gradient Boosting\n",
    "\n",
    "Напомним фундаментальные отличия баггинга от бустинга:\n",
    "* Баггинг (Bagging) - подход, где вы берете случайные подмножества данных, обучаете алгоритмы и берете простое математическое ожидание, чтобы найти класс.\n",
    "* Бустинг (Boosting) - подход, похожий на баггинг, однако отбор множеств производится более интеллектуально. Мы последовательно даем б**о**льший вес наблюдениям, которые сложно классифицировать.\n",
    "\n",
    "Рассмотрим простой пример:\n",
    "Предположим, у нас есть модель $M$, которую мы бы хотели улучшить. Сейчас вы видите, что модель имеет точность $80%$ (по любой метрике). \n",
    "\n",
    "Что можно сделать для решения поставленной задачи?\n",
    "\n",
    "Одним из простых способов является построить другую модель, используя новое множество входных переменных и попытаться использовать ансамбльный алгоритм. С другой стороны, можно предложить простой способ.\n",
    "\n",
    "$$ Y = M(X) + error$$\n",
    "\n",
    "А что если мы способны рассмотреть эту ошибку не как \"белый шум\", а как некоторую корреляцию с выходным значением ($Y$)? Что если мы построим модель на базе этой ошибки?\n",
    "\n",
    "$$ error = G(x) + error_2 $$\n",
    "\n",
    "Возможно, Вы увидете что точность улучшится, и станет, скажем $84%$. Сделаем еще один шаг и проведем регрессию $error_2$.\n",
    "\n",
    "$$ error_2 = H(x) + error_3 $$.\n",
    "\n",
    "Сейчас, мы можем скомбинировать все эти модели вместе:\n",
    "\n",
    "$$ Y = M(x) + G(x) + H(x) + error_3$$\n",
    "\n",
    "Возможно, это приведет к повышению точности, даже больше чем $84%$. А что если мы найдем оптимальные весовые коэффициенты для каждой из трех предиктивных моделей $M(x)$, $G(x)$ и $H(x)$?\n",
    "\n",
    "$$ Y = \\alpha M(x) + \\beta G(x) + \\gamma H(x) + error_4$$\n",
    "\n",
    "Если мы нашли хорошие веса, то, возможно, мы еще улучшим модель. Это основной принцип, лежащий в основе бустинга. \n",
    "\n",
    "### А что там с градиентным бустингом?\n",
    "\n",
    "\n",
    "В градиентном бустинге (gradient boosting) обучаются последовательно несколько моделей. **Каждая новая модель минимизирует функцию потерь (loss function)** (например, $y=ax+b+e$, где $e$ - терм, репрезентующий ошибку) **всей системы, с использованием алгоритма градиентного спуска** (Gradient Descent method). Процедура обучения последовательно настраивает новые модели для того, чтобы предоставить более точную оценку целевой переменной.\n",
    "\n",
    "Главная идея, стоящая за этим алгоритмом состоит в том, чтобы конструировать новые базовые классификаторы (new base learners) которые могут максимально коррелировать с отрицательным градиентом функции потерь, ассоциированной со всем ансамблем. \n",
    "\n",
    "Примечание: дальнейшее изложение сделано на базе статьи http://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/\n",
    "\n",
    "Вспомним алгоритм **AdaBoost** и принцип его работы.\n",
    "\n",
    "AdaBoost работает, \"взвешивая\" наблюдения, давая больший вес тем наблюденеиям, который некорректно классифицируются и меньший вес тем наблюдениям, которые уже достаточно хорошо классифицируются.\n",
    "\n",
    "Новые \"слабые классификаторы\" (weak learners) добавляются последовательно, так, что они фокусируются на более сложных паттернах в тренировочной выборке.\n",
    "\n",
    "Предсказания производятся по принципу мажоритарного голосования от \"слабых классификаторов\", взвешенных в соответствии с их индивидуальными показателями точности.\n",
    "\n",
    "Еще одна ссылка с объяснением алгоритма AdaBoost: \n",
    "Boosting and AdaBoost for Machine Learning (http://machinelearningmastery.com/boosting-and-adaboost-for-machine-learning/)\n",
    "\n",
    "#### Обобщение AdaBoost как градиентный бустинг (Gradient Boosting)\n",
    "\n",
    "AdaBoost и схожие алгоритмами были \"переделаны\" в статистическом фреймворке, предложенном Brieman'ом и названным им алгоритмами ARCing.\n",
    "\n",
    "*Arcing - акроним для Adaptive Reweighting and Combining.* Каждый шаг в алгоритме arcing заключается во взвешенной минимизации, следующей за повторными вычислениями (recomputation) [классификаторов] и взвешиванием входных значений (weighted input).\n",
    "\n",
    "Этот фреймворк в дальнейшем развивался Friedman'ом и назывался Gradient Boosting Machines. Позже он стал называться градиентным бустингом (gradient boosting) или градиентным бустингом деревьев (gradient tree boosting).\n",
    "\n",
    "Этот статистический фреймворк рассматривал бустинг как проблему численной оптимизации, где целью было оптимизировать функцию потреь модели, посредством добавления \"слабых классификаторов\" используя как процедуру алгоритм градиентного спуска.\n",
    "\n",
    "Этот класс алгоритмов был описан как поэтапная аддитивная модель (stage-wise additive model). Это происходило из-за того, что каждый новый \"слабый классификатор\" добавлялся пошагово, а существующие \"слабые классификаторы\" модели \"замораживались\" и оставались неизменными.\n",
    "\n",
    "Обобщение, позволяющее произвольные дифференцируемые функции потерь, расширяет технику, применяемую для решения задач бинарной классификации к задачам регрессии и к задачам мультиклассовой классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как работает градиентный бустинг?\n",
    "\n",
    "Градиентный бустинг включает в себя три элемента:\n",
    "* A loss function to be optimized.\n",
    "* A weak learner to make predictions.\n",
    "* An additive model to add weak learners to minimize the loss function.\n",
    "\n",
    "##### 1. Функция потерь (loss function)\n",
    "\n",
    "Функция потерь используется в зависимости от типа решаемой проблемы.\n",
    "\n",
    "Она **должна быть дифференцируемой**, но поддерживается множество стандартных функций потерь и Вы можете определить собственную.\n",
    "\n",
    "Например, регрессия может использовать квадратичную функцию потерь, а классификация м. использовать логарифмическую функцию потерь.\n",
    "\n",
    "**Контрольный вопрос: приведите эти функции**\n",
    "\n",
    "Преимущество градиентного бустинга состоит в том, что новый алгоритм бустинга не нужно выводить для каждой функции потерь, которую мы можем захотеть использовать, а вместо этого, используется достаточно общий фреймворк, который позволяет использовать  любую дифференцируемую функцию потерь.\n",
    "\n",
    "##### 2. Слабые классификаторы (weak learner)\n",
    "\n",
    "Деревья решений используются как слабые классификаторы в алгоритме градиентного бустинга.\n",
    "\n",
    "В частности, можно использовать регрессионные деревья, которые дают действительные значения для разбиений, и в качестве выходного значения можно использовать их среднее.\n",
    "\n",
    "Деревья конструируются \"жадным\" способом (см. лекцию о деревьях решений), выбирая наилучшее разбиения базируясь на информационных критериях, или минимизируя функции потерь.\n",
    "\n",
    "Изначально, так же как и в AdaBoost, используются очень короткие деревья решений, которые имеют только одно разбиение, называемое *решающей пень (decision stump)* .Большие деревья могут использоваться обычно с уровнями от 4 до 8.\n",
    "\n",
    "Зачастую, выставляют ограничения на слабые классификаторы, например максимальное число узлов, разделений или листьев. Это гарантирует, что базовые классификаторы останутся достаточно слабыми, но они могут по прежнему строится жадным способом.\n",
    "\n",
    "##### 3.Аддитивная модель (additive model)\n",
    "\n",
    "Деревья добавляются по одному и существующие деревья в модели не изменяются. Процедура градиентного спуска используется для минимизации функции потерь при добавлении деревьев.\n",
    "\n",
    "Обычно градиентный спуск используется, чтобы минимизировать множество параметров, таких как коэффициенты в уравнении регрессии, или веса в нейронной сети.\n",
    "\n",
    "После вычисления ошибки, или потери (loss), веса обновляются таким образом, чтобы минимизировать эту ошибку.\n",
    "\n",
    "Теперь, вместо параметров, мы имеем слабые классификаторы (weak learner) или деревья решений специального вида. После вычисления функции потерь, выполняется процедура градиентного спуска. Мы должны добавить к модели дерево таким образом, чтобы уменьшилась функция потреь (т.е. двигаясь по градиенту). Мы делаем это параметризуя дерево, затем модифицируя параметры дерева и двигаемся в правильном направлении (уменьшая потери).\n",
    "\n",
    "Этот подход называется функциональным градиентным спуском, или градиентным спуском с функциями.\n",
    "\n",
    "Выъод нового дерева затем добавляется к выходным значениям существующей последовательности деревьев так, скорректировать или улучшить функциональный выход модели.\n",
    "\n",
    "Обучение прекращается, когда достигнуто определенное фиксированное число дереьев, добавленных в модель, или функция потерь достигает приемлемого значения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В scikit-learn используется Gradient Tree Boosting, что является обобщением бустинга на произвольные дифференцируемые функции потерь. GTB может использоваться как для решения задач регрессии, так и для решения задач классификации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier #For Classification\n",
    "from sklearn.ensemble import GradientBoostingRegressor #For Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметры: \n",
    "* **n_estimators** - контролирует число базовых классификаторов (weak learners);\n",
    "* **learning_rate** - контролирует вклад базовых классификаторов в финальную комбинацию. Существует компромисс между параметрами *learning_rate* и *n_estimators*.\n",
    "* **max_depth** - максимальная глубина ограничивает число узлов в дереве. Этот параметра настраивается для лучшей производительности, лучшее значение зависит от взаимодействия входных переменных.\n",
    "\n",
    "Также можно настраивать функцию потерь (loss function) для лучшей производительности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Литература:\n",
    "* https://www.analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/\n",
    "* https://www.analyticsvidhya.com/blog/2016/04/complete-tutorial-tree-based-modeling-scratch-in-python/\n",
    "* https://www.analyticsvidhya.com/blog/2015/08/introduction-ensemble-learning/\n",
    "* http://www.levvu.narod.ru/Machine_Learning_LTU_7.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
